#!/usr/bin/env python3
"""
DocAgent Indexer
–°–æ–∑–¥–∞—ë—Ç JSON –∏–Ω–¥–µ–∫—Å—ã –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞ –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏
"""

import os
import sys
import json
import yaml
import argparse
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional
from loguru import logger

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logger.remove()
logger.add(sys.stderr, format="<green>{time:HH:mm:ss}</green> | <level>{level: <8}</level> | <level>{message}</level>")


class DocAgentIndexer:
    """–ö–ª–∞—Å—Å –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∏–Ω–¥–µ–∫—Å–æ–≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏"""
    
    def __init__(self, base_dir: str = "knowledge_base"):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
        
        Args:
            base_dir: –ë–∞–∑–æ–≤–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å markdown —Ñ–∞–π–ª–∞–º–∏
        """
        self.base_dir = Path(base_dir)
        
        logger.info(f"DocAgentIndexer initialized")
        logger.info(f"Base dir: {self.base_dir.absolute()}")
    
    def parse_yaml_frontmatter(self, file_path: Path) -> Optional[Dict]:
        """
        –ò–∑–≤–ª–µ—á—å YAML front matter –∏–∑ markdown —Ñ–∞–π–ª–∞
        
        Args:
            file_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ –∏–ª–∏ None
        """
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –Ω–∞–ª–∏—á–∏–µ front matter
            if not content.startswith('---\n'):
                return None
            
            # –†–∞–∑–¥–µ–ª–∏—Ç—å –Ω–∞ —á–∞—Å—Ç–∏
            parts = content.split('---\n', 2)
            if len(parts) < 3:
                return None
            
            # –ü–∞—Ä—Å–∏—Ç—å YAML
            metadata = yaml.safe_load(parts[1])
            return metadata
            
        except Exception as e:
            logger.error(f"Error parsing {file_path.name}: {e}")
            return None
    
    def build_app_index(self, app_name: str, output_file: Optional[str] = None) -> Dict:
        """
        –°–æ–∑–¥–∞—Ç—å –∏–Ω–¥–µ–∫—Å –¥–ª—è –æ–¥–Ω–æ–≥–æ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
        
        Args:
            app_name: –ò–º—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
            output_file: –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è JSON (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –∏–Ω–¥–µ–∫—Å–æ–º
        """
        app_dir = self.base_dir / app_name
        
        if not app_dir.exists():
            logger.error(f"App directory not found: {app_dir}")
            return {}
        
        logger.info(f"üîç Building index for: {app_name}")
        
        # –ù–∞–π—Ç–∏ –≤—Å–µ markdown —Ñ–∞–π–ª—ã
        md_files = list(app_dir.glob("*.md"))
        logger.info(f"   Found: {len(md_files)} markdown files")
        
        # –°–æ–±—Ä–∞—Ç—å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        pages = []
        total_words = 0
        categories = {}
        tags_set = set()
        
        for md_file in md_files:
            metadata = self.parse_yaml_frontmatter(md_file)
            
            if not metadata:
                logger.warning(f"No metadata: {md_file.name}")
                continue
            
            # –î–æ–±–∞–≤–∏—Ç—å –≤ —Å–ø–∏—Å–æ–∫ —Å—Ç—Ä–∞–Ω–∏—Ü
            pages.append(metadata)
            
            # –ü–æ–¥—Å—á–∏—Ç–∞—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            total_words += metadata.get('word_count', 0)
            
            # –ö–∞—Ç–µ–≥–æ—Ä–∏–∏
            category = metadata.get('category', 'uncategorized')
            categories[category] = categories.get(category, 0) + 1
            
            # –¢–µ–≥–∏
            for tag in metadata.get('tags', []):
                tags_set.add(tag)
        
        # –°–æ–∑–¥–∞—Ç—å –∏–Ω–¥–µ–∫—Å
        index = {
            'app': app_name,
            'app_full_name': pages[0].get('app_full_name', app_name) if pages else app_name,
            'version': '1.0.0',
            'last_update': datetime.now().isoformat(),
            'total_pages': len(pages),
            'total_words': total_words,
            'categories': categories,
            'tags': sorted(list(tags_set)),
            'pages': pages
        }
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        logger.info(f"   Pages:      {index['total_pages']}")
        logger.info(f"   Words:      {index['total_words']:,}")
        logger.info(f"   Categories: {len(categories)}")
        logger.info(f"   Tags:       {len(tags_set)}")
        
        # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ —Ñ–∞–π–ª –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω
        if output_file:
            output_path = Path(output_file)
            output_path.parent.mkdir(parents=True, exist_ok=True)
            
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(index, f, indent=2, ensure_ascii=False)
            
            logger.success(f"‚úÖ Index saved: {output_path}")
        else:
            # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
            index_path = app_dir / 'index.json'
            with open(index_path, 'w', encoding='utf-8') as f:
                json.dump(index, f, indent=2, ensure_ascii=False)
            
            logger.success(f"‚úÖ Index saved: {index_path}")
        
        return index
    
    def build_global_index(self, output_file: str = "global_index.json") -> Dict:
        """
        –°–æ–∑–¥–∞—Ç—å –≥–ª–æ–±–∞–ª—å–Ω—ã–π –∏–Ω–¥–µ–∫—Å –≤—Å–µ—Ö –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π
        
        Args:
            output_file: –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
            
        Returns:
            –ì–ª–æ–±–∞–ª—å–Ω—ã–π –∏–Ω–¥–µ–∫—Å
        """
        if not self.base_dir.exists():
            logger.error(f"Base directory not found: {self.base_dir}")
            return {}
        
        logger.info(f"üìö Building global index")
        
        # –ù–∞–π—Ç–∏ –≤—Å–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
        app_dirs = [d for d in self.base_dir.iterdir() if d.is_dir()]
        logger.info(f"   Found: {len(app_dirs)} apps")
        
        apps = []
        total_pages = 0
        total_words = 0
        
        for app_dir in app_dirs:
            app_name = app_dir.name
            
            # –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∏–Ω–¥–µ–∫—Å
            app_index_path = app_dir / 'index.json'
            
            if app_index_path.exists():
                with open(app_index_path, 'r', encoding='utf-8') as f:
                    app_index = json.load(f)
            else:
                # –ü–æ—Å—Ç—Ä–æ–∏—Ç—å –∏–Ω–¥–µ–∫—Å –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
                logger.info(f"   Building missing index for: {app_name}")
                app_index = self.build_app_index(app_name)
            
            # –î–æ–±–∞–≤–∏—Ç—å –≤ —Å–ø–∏—Å–æ–∫
            apps.append({
                'app': app_name,
                'app_full_name': app_index.get('app_full_name', app_name),
                'total_pages': app_index.get('total_pages', 0),
                'total_words': app_index.get('total_words', 0),
                'categories': app_index.get('categories', {}),
                'tags': app_index.get('tags', []),
                'last_update': app_index.get('last_update', '')
            })
            
            total_pages += app_index.get('total_pages', 0)
            total_words += app_index.get('total_words', 0)
        
        # –°–æ–∑–¥–∞—Ç—å –≥–ª–æ–±–∞–ª—å–Ω—ã–π –∏–Ω–¥–µ–∫—Å
        global_index = {
            'version': '1.0.0',
            'generated': datetime.now().isoformat(),
            'total_apps': len(apps),
            'total_pages': total_pages,
            'total_words': total_words,
            'apps': apps
        }
        
        # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å
        output_path = Path(output_file)
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(global_index, f, indent=2, ensure_ascii=False)
        
        logger.success(f"‚úÖ Global index saved: {output_path}")
        logger.info(f"\nüìä Global Stats:")
        logger.info(f"   Apps:  {global_index['total_apps']}")
        logger.info(f"   Pages: {global_index['total_pages']}")
        logger.info(f"   Words: {global_index['total_words']:,}")
        
        return global_index
    
    def search_index(self, query: str, app_name: Optional[str] = None) -> List[Dict]:
        """
        –ü–æ–∏—Å–∫ –ø–æ –∏–Ω–¥–µ–∫—Å–∞–º
        
        Args:
            query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
            app_name: –§–∏–ª—å—Ç—Ä –ø–æ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—é (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            
        Returns:
            –°–ø–∏—Å–æ–∫ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Å—Ç—Ä–∞–Ω–∏—Ü
        """
        query_lower = query.lower()
        results = []
        
        # –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –≥–¥–µ –∏—Å–∫–∞—Ç—å
        if app_name:
            app_dirs = [self.base_dir / app_name]
        else:
            app_dirs = [d for d in self.base_dir.iterdir() if d.is_dir()]
        
        for app_dir in app_dirs:
            index_path = app_dir / 'index.json'
            
            if not index_path.exists():
                continue
            
            with open(index_path, 'r', encoding='utf-8') as f:
                index = json.load(f)
            
            # –ü–æ–∏—Å–∫ –ø–æ —Å—Ç—Ä–∞–Ω–∏—Ü–∞–º
            for page in index.get('pages', []):
                # –ü–æ–∏—Å–∫ –≤ –∑–∞–≥–æ–ª–æ–≤–∫–µ
                if query_lower in page.get('title', '').lower():
                    results.append(page)
                    continue
                
                # –ü–æ–∏—Å–∫ –≤ —Ç–µ–≥–∞—Ö
                if any(query_lower in tag.lower() for tag in page.get('tags', [])):
                    results.append(page)
                    continue
                
                # –ü–æ–∏—Å–∫ –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
                if query_lower in page.get('category', '').lower():
                    results.append(page)
        
        return results


def main():
    """–¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞ CLI"""
    parser = argparse.ArgumentParser(
        description="DocAgent Indexer - Build JSON indexes for documentation",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Build index for specific app
  python build_index.py --app dbgpt
  
  # Build global index
  python build_index.py --all --output global_index.json
  
  # Search in indexes
  python build_index.py --search "RAG" --app dbgpt
        """
    )
    
    parser.add_argument(
        '--app',
        type=str,
        help='ID –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏'
    )
    
    parser.add_argument(
        '--all',
        action='store_true',
        help='–ü–æ—Å—Ç—Ä–æ–∏—Ç—å –≥–ª–æ–±–∞–ª—å–Ω—ã–π –∏–Ω–¥–µ–∫—Å –≤—Å–µ—Ö –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π'
    )
    
    parser.add_argument(
        '--base-dir',
        type=str,
        default='knowledge_base',
        help='–ë–∞–∑–æ–≤–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: knowledge_base)'
    )
    
    parser.add_argument(
        '--output',
        type=str,
        help='–ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∏–Ω–¥–µ–∫—Å–∞'
    )
    
    parser.add_argument(
        '--search',
        type=str,
        help='–ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å'
    )
    
    parser.add_argument(
        '--verbose',
        action='store_true',
        help='–ü–æ–¥—Ä–æ–±–Ω—ã–π –≤—ã–≤–æ–¥'
    )
    
    args = parser.parse_args()
    
    try:
        # –°–æ–∑–¥–∞—Ç—å indexer
        indexer = DocAgentIndexer(base_dir=args.base_dir)
        
        # –í—ã–ø–æ–ª–Ω–∏—Ç—å –∫–æ–º–∞–Ω–¥—É
        if args.search:
            results = indexer.search_index(args.search, app_name=args.app)
            
            logger.info(f"\nüîç Search results for '{args.search}':")
            logger.info(f"   Found: {len(results)} pages\n")
            
            for i, page in enumerate(results, 1):
                logger.info(f"{i}. {page.get('title', 'Untitled')}")
                logger.info(f"   App: {page.get('app', 'unknown')}")
                logger.info(f"   URL: {page.get('source', 'N/A')}")
                logger.info("")
        
        elif args.all:
            output = args.output or 'global_index.json'
            indexer.build_global_index(output_file=output)
        
        elif args.app:
            indexer.build_app_index(args.app, output_file=args.output)
        
        else:
            parser.print_help()
            logger.warning("\nNo action specified. Use --app, --all, or --search")
    
    except KeyboardInterrupt:
        logger.warning("\n‚ö†Ô∏è Interrupted by user")
        sys.exit(1)
    except Exception as e:
        logger.error(f"‚ùå Fatal error: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
