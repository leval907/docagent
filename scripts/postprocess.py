#!/usr/bin/env python3
"""
DocAgent Postprocessor
–î–æ–±–∞–≤–ª—è–µ—Ç YAML front matter –∫ —Å–æ–±—Ä–∞–Ω–Ω—ã–º markdown —Ñ–∞–π–ª–∞–º
"""

import os
import sys
import re
import yaml
import hashlib
import argparse
from pathlib import Path
from datetime import datetime
from typing import Dict, Optional, List
from loguru import logger

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logger.remove()
logger.add(sys.stderr, format="<green>{time:HH:mm:ss}</green> | <level>{level: <8}</level> | <level>{message}</level>")


class MetadataInjector:
    """–ö–ª–∞—Å—Å –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –≤ markdown —Ñ–∞–π–ª—ã"""
    
    def __init__(self, base_dir: str = "knowledge_base", config_path: str = "config/sources.yaml"):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
        
        Args:
            base_dir: –ë–∞–∑–æ–≤–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å markdown —Ñ–∞–π–ª–∞–º–∏
            config_path: –ü—É—Ç—å –∫ –∫–æ–Ω—Ñ–∏–≥—É –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
        """
        self.base_dir = Path(base_dir)
        self.config_path = Path(config_path)
        self.config = self._load_config()
        
        logger.info(f"MetadataInjector initialized")
        logger.info(f"Base dir: {self.base_dir.absolute()}")
    
    def _load_config(self) -> Dict:
        """–ó–∞–≥—Ä—É–∑–∏—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é"""
        if self.config_path.exists():
            with open(self.config_path, 'r', encoding='utf-8') as f:
                return yaml.safe_load(f)
        return {}
    
    def extract_title(self, content: str) -> str:
        """
        –ò–∑–≤–ª–µ—á—å –∑–∞–≥–æ–ª–æ–≤–æ–∫ –∏–∑ markdown
        
        Args:
            content: –°–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞
            
        Returns:
            –ó–∞–≥–æ–ª–æ–≤–æ–∫ –∏–ª–∏ –ø—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞
        """
        lines = content.split('\n')
        for line in lines:
            # –ò—â–µ–º –ø–µ—Ä–≤—ã–π H1 –∑–∞–≥–æ–ª–æ–≤–æ–∫
            match = re.match(r'^#\s+(.+)$', line.strip())
            if match:
                return match.group(1).strip()
        return ""
    
    def extract_metadata_from_content(self, content: str) -> Dict:
        """
        –ò–∑–≤–ª–µ—á—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∏–∑ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
        
        Args:
            content: –°–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
        """
        metadata = {
            'word_count': len(content.split()),
            'line_count': len(content.split('\n')),
            'has_code': '```' in content,
        }
        
        # –ò–∑–≤–ª–µ—á—å –∑–∞–≥–æ–ª–æ–≤–∫–∏ –≤—Å–µ—Ö —É—Ä–æ–≤–Ω–µ–π
        headers = re.findall(r'^#{1,6}\s+(.+)$', content, re.MULTILINE)
        metadata['headers_count'] = len(headers)
        
        # –ò–∑–≤–ª–µ—á—å —Å—Å—ã–ª–∫–∏
        links = re.findall(r'\[([^\]]+)\]\(([^\)]+)\)', content)
        metadata['links_count'] = len(links)
        
        # –ò–∑–≤–ª–µ—á—å –±–ª–æ–∫–∏ –∫–æ–¥–∞
        code_blocks = re.findall(r'```(\w+)?\n(.*?)```', content, re.DOTALL)
        if code_blocks:
            languages = [lang for lang, _ in code_blocks if lang]
            metadata['code_languages'] = list(set(languages))
            metadata['code_blocks_count'] = len(code_blocks)
        
        return metadata
    
    def calculate_file_hash(self, file_path: Path) -> str:
        """
        –í—ã—á–∏—Å–ª–∏—Ç—å SHA256 —Ö–µ—à —Ñ–∞–π–ª–∞
        
        Args:
            file_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É
            
        Returns:
            –•–µ—à —Å—Ç—Ä–æ–∫–∞
        """
        sha256_hash = hashlib.sha256()
        with open(file_path, "rb") as f:
            for byte_block in iter(lambda: f.read(4096), b""):
                sha256_hash.update(byte_block)
        return sha256_hash.hexdigest()
    
    def has_yaml_frontmatter(self, content: str) -> bool:
        """
        –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –µ—Å—Ç—å –ª–∏ —É–∂–µ YAML front matter
        
        Args:
            content: –°–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞
            
        Returns:
            True –µ—Å–ª–∏ –µ—Å—Ç—å
        """
        return content.startswith('---\n')
    
    def add_yaml_frontmatter(
        self,
        file_path: Path,
        app_name: str,
        source_url: Optional[str] = None,
        force: bool = False
    ) -> bool:
        """
        –î–æ–±–∞–≤–∏—Ç—å YAML front matter –∫ —Ñ–∞–π–ª—É
        
        Args:
            file_path: –ü—É—Ç—å –∫ markdown —Ñ–∞–π–ª—É
            app_name: –ò–º—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
            source_url: URL –∏—Å—Ç–æ—á–Ω–∏–∫–∞
            force: –ü–µ—Ä–µ–∑–∞–ø–∏—Å–∞—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π front matter
            
        Returns:
            True –µ—Å–ª–∏ —É—Å–ø–µ—à–Ω–æ
        """
        if not file_path.exists():
            logger.error(f"File not found: {file_path}")
            return False
        
        # –ü—Ä–æ—á–∏—Ç–∞—Ç—å —Ñ–∞–π–ª
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –µ—Å—Ç—å –ª–∏ —É–∂–µ front matter
        if self.has_yaml_frontmatter(content) and not force:
            logger.debug(f"Skipping (already has frontmatter): {file_path.name}")
            return False
        
        # –ï—Å–ª–∏ –µ—Å—Ç—å frontmatter –∏ force=True, —É–¥–∞–ª–∏—Ç—å —Å—Ç–∞—Ä—ã–π
        if self.has_yaml_frontmatter(content) and force:
            parts = content.split('---\n', 2)
            if len(parts) >= 3:
                content = parts[2]
        
        # –ò–∑–≤–ª–µ—á—å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        title = self.extract_title(content) or file_path.stem.replace('_', ' ').title()
        content_metadata = self.extract_metadata_from_content(content)
        file_hash = self.calculate_file_hash(file_path)
        
        # –ü–æ–ª—É—á–∏—Ç—å –∫–æ–Ω—Ñ–∏–≥ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
        app_config = self.config.get('apps', {}).get(app_name, {})
        
        # –ü–æ—Å—Ç—Ä–æ–∏—Ç—å URL –∏—Å—Ç–æ—á–Ω–∏–∫–∞
        if not source_url and app_config:
            base_url = app_config.get('url', '')
            # –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å URL –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
            if base_url:
                # –£–±—Ä–∞—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å–µ–≥–º–µ–Ω—Ç –ø—É—Ç–∏ –∏–∑ base_url
                base_url = base_url.rstrip('/')
                file_slug = file_path.stem.replace('_', '-')
                source_url = f"{base_url}/{file_slug}"
        
        # –°–æ–∑–¥–∞—Ç—å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        metadata = {
            'title': title,
            'source': source_url or '',
            'app': app_name,
            'app_full_name': app_config.get('name', app_name),
            'category': app_config.get('category', ''),
            'tags': app_config.get('tags', []),
            'date_crawled': datetime.now().isoformat(),
            'last_updated': datetime.now().isoformat(),
            'file_path': str(file_path.relative_to(self.base_dir.parent)),
            'word_count': content_metadata['word_count'],
            'has_code': content_metadata['has_code'],
            'code_languages': content_metadata.get('code_languages', []),
            'headers_count': content_metadata['headers_count'],
            'links_count': content_metadata['links_count'],
            'file_hash': file_hash,
        }
        
        # –°—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å YAML
        yaml_str = yaml.dump(metadata, allow_unicode=True, sort_keys=False)
        
        # –°–æ–±—Ä–∞—Ç—å –Ω–æ–≤—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç
        new_content = f"---\n{yaml_str}---\n\n{content}"
        
        # –ó–∞–ø–∏—Å–∞—Ç—å –æ–±—Ä–∞—Ç–Ω–æ
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(new_content)
        
        logger.success(f"‚úÖ Added metadata: {file_path.name}")
        return True
    
    def process_app_docs(self, app_name: str, force: bool = False) -> Dict[str, int]:
        """
        –û–±—Ä–∞–±–æ—Ç–∞—Ç—å –≤—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
        
        Args:
            app_name: –ò–º—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
            force: –ü–µ—Ä–µ–∑–∞–ø–∏—Å–∞—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            
        Returns:
            –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ {processed, skipped, errors}
        """
        app_dir = self.base_dir / app_name
        
        if not app_dir.exists():
            logger.error(f"App directory not found: {app_dir}")
            return {'processed': 0, 'skipped': 0, 'errors': 0}
        
        logger.info(f"üîç Processing app: {app_name}")
        logger.info(f"   Directory: {app_dir}")
        
        stats = {'processed': 0, 'skipped': 0, 'errors': 0}
        
        # –ù–∞–π—Ç–∏ –≤—Å–µ markdown —Ñ–∞–π–ª—ã
        md_files = list(app_dir.glob("*.md"))
        logger.info(f"   Found: {len(md_files)} markdown files")
        
        for md_file in md_files:
            try:
                success = self.add_yaml_frontmatter(md_file, app_name, force=force)
                if success:
                    stats['processed'] += 1
                else:
                    stats['skipped'] += 1
            except Exception as e:
                logger.error(f"‚ùå Error processing {md_file.name}: {e}")
                stats['errors'] += 1
        
        logger.info(f"\nüìä Stats for {app_name}:")
        logger.info(f"   Processed: {stats['processed']}")
        logger.info(f"   Skipped:   {stats['skipped']}")
        logger.info(f"   Errors:    {stats['errors']}")
        
        return stats
    
    def process_all_apps(self, force: bool = False) -> Dict[str, Dict[str, int]]:
        """
        –û–±—Ä–∞–±–æ—Ç–∞—Ç—å –≤—Å–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
        
        Args:
            force: –ü–µ—Ä–µ–∑–∞–ø–∏—Å–∞—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            
        Returns:
            –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –≤—Å–µ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è–º
        """
        if not self.base_dir.exists():
            logger.error(f"Base directory not found: {self.base_dir}")
            return {}
        
        # –ù–∞–π—Ç–∏ –≤—Å–µ –ø–æ–¥–¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ (–ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è)
        app_dirs = [d for d in self.base_dir.iterdir() if d.is_dir()]
        
        logger.info(f"üìö Processing {len(app_dirs)} apps")
        
        all_stats = {}
        for app_dir in app_dirs:
            app_name = app_dir.name
            logger.info(f"\n{'='*60}")
            stats = self.process_app_docs(app_name, force=force)
            all_stats[app_name] = stats
        
        # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        logger.info(f"\n{'='*60}")
        logger.info("üìä Total Summary:")
        
        total_processed = sum(s['processed'] for s in all_stats.values())
        total_skipped = sum(s['skipped'] for s in all_stats.values())
        total_errors = sum(s['errors'] for s in all_stats.values())
        
        logger.info(f"   Apps:      {len(all_stats)}")
        logger.info(f"   Processed: {total_processed}")
        logger.info(f"   Skipped:   {total_skipped}")
        logger.info(f"   Errors:    {total_errors}")
        
        return all_stats


def main():
    """–¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞ CLI"""
    parser = argparse.ArgumentParser(
        description="DocAgent Postprocessor - Add YAML front matter to markdown files",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Process specific app
  python postprocess.py --app dbgpt
  
  # Process all apps
  python postprocess.py --all
  
  # Force overwrite existing metadata
  python postprocess.py --app dbgpt --force
        """
    )
    
    parser.add_argument(
        '--app',
        type=str,
        help='ID –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏'
    )
    
    parser.add_argument(
        '--all',
        action='store_true',
        help='–û–±—Ä–∞–±–æ—Ç–∞—Ç—å –≤—Å–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è'
    )
    
    parser.add_argument(
        '--base-dir',
        type=str,
        default='knowledge_base',
        help='–ë–∞–∑–æ–≤–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å markdown —Ñ–∞–π–ª–∞–º–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: knowledge_base)'
    )
    
    parser.add_argument(
        '--config',
        type=str,
        default='config/sources.yaml',
        help='–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: config/sources.yaml)'
    )
    
    parser.add_argument(
        '--force',
        action='store_true',
        help='–ü–µ—Ä–µ–∑–∞–ø–∏—Å–∞—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ'
    )
    
    parser.add_argument(
        '--verbose',
        action='store_true',
        help='–ü–æ–¥—Ä–æ–±–Ω—ã–π –≤—ã–≤–æ–¥'
    )
    
    args = parser.parse_args()
    
    # –ù–∞—Å—Ç—Ä–æ–∏—Ç—å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
    if args.verbose:
        logger.level("DEBUG")
    
    try:
        # –°–æ–∑–¥–∞—Ç—å injector
        injector = MetadataInjector(base_dir=args.base_dir, config_path=args.config)
        
        # –í—ã–ø–æ–ª–Ω–∏—Ç—å –∫–æ–º–∞–Ω–¥—É
        if args.all:
            injector.process_all_apps(force=args.force)
        elif args.app:
            injector.process_app_docs(args.app, force=args.force)
        else:
            parser.print_help()
            logger.warning("\nNo action specified. Use --app or --all")
    
    except KeyboardInterrupt:
        logger.warning("\n‚ö†Ô∏è Interrupted by user")
        sys.exit(1)
    except Exception as e:
        logger.error(f"‚ùå Fatal error: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
