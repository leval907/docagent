#!/usr/bin/env python3
"""
–ó–∞–≥—Ä—É–∑–∫–∞ —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∞ –î–î–° –∏–∑ –≤—ã–≤–µ—Ä–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ dds_final_v3_corrected.xlsx
–°–æ–∑–¥–∞–Ω–∏–µ –∏–µ—Ä–∞—Ä—Ö–∏–∏: –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ ‚Üí –≥—Ä—É–ø–ø—ã ‚Üí —Å—Ç–∞—Ç—å–∏
"""

import pandas as pd
import psycopg2
from psycopg2.extras import execute_batch
import sys

DB_CONFIG = {
    'host': 'localhost',
    'port': 5432,
    'database': 'analytics',
    'user': 'analytics_user',
    'password': 'analytics_secure_2025'
}

EXCEL_FILE = '/opt/docagent/data/osv_revenue_0925/input/info_docs/Postgres/correct_2/dds_final_v3_corrected.xlsx'

# –ú–∞–ø–ø–∏–Ω–≥ –∫–∞—Ç–µ–≥–æ—Ä–∏–π –Ω–∞ –∫–æ–¥
CATEGORY_MAPPING = {
    '–û–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω–∞—è –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç—å - –ü–æ—Å—Ç—É–ø–ª–µ–Ω–∏—è': 'OPS_IN',
    '–û–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω–∞—è –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç—å - –ü–ª–∞—Ç–µ–∂–∏': 'OPS_OUT',
    '–ò–Ω–≤–µ—Å—Ç–∏—Ü–∏–æ–Ω–Ω–∞—è –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç—å - –ü–æ—Å—Ç—É–ø–ª–µ–Ω–∏—è': 'INV_IN',
    '–ò–Ω–≤–µ—Å—Ç–∏—Ü–∏–æ–Ω–Ω–∞—è –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç—å - –ü–ª–∞—Ç–µ–∂–∏': 'INV_OUT',
    '–§–∏–Ω–∞–Ω—Å–æ–≤–∞—è –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç—å - –ü–æ—Å—Ç—É–ø–ª–µ–Ω–∏—è': 'FIN_IN',
    '–§–∏–Ω–∞–Ω—Å–æ–≤–∞—è –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç—å - –ü–ª–∞—Ç–µ–∂–∏': 'FIN_OUT',
    '–í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ –ø–µ—Ä–µ–≤–æ–¥—ã': 'TRF'
}

# –ú–∞–ø–ø–∏–Ω–≥ –≤–∏–¥–∞ –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
ACTIVITY_MAPPING = {
    '–û–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω–∞—è –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç—å - –ü–æ—Å—Ç—É–ø–ª–µ–Ω–∏—è': 'OPERATING',
    '–û–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω–∞—è –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç—å - –ü–ª–∞—Ç–µ–∂–∏': 'OPERATING',
    '–ò–Ω–≤–µ—Å—Ç–∏—Ü–∏–æ–Ω–Ω–∞—è –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç—å - –ü–æ—Å—Ç—É–ø–ª–µ–Ω–∏—è': 'INVESTING',
    '–ò–Ω–≤–µ—Å—Ç–∏—Ü–∏–æ–Ω–Ω–∞—è –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç—å - –ü–ª–∞—Ç–µ–∂–∏': 'INVESTING',
    '–§–∏–Ω–∞–Ω—Å–æ–≤–∞—è –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç—å - –ü–æ—Å—Ç—É–ø–ª–µ–Ω–∏—è': 'FINANCING',
    '–§–∏–Ω–∞–Ω—Å–æ–≤–∞—è –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç—å - –ü–ª–∞—Ç–µ–∂–∏': 'FINANCING',
    '–í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ –ø–µ—Ä–µ–≤–æ–¥—ã': 'TRANSFER'
}

def load_excel():
    """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ Excel"""
    print(f"üìÑ –ß—Ç–µ–Ω–∏–µ: {EXCEL_FILE}")
    df = pd.read_excel(EXCEL_FILE, sheet_name='–°–ø—Ä–∞–≤–æ—á–Ω–∏–∫ –î–î–°')
    
    # –§–∏–ª—å—Ç—Ä –∞–∫—Ç–∏–≤–Ω—ã—Ö
    df = df[df['–ê–∫—Ç–∏–≤–Ω–æ'] == '–î–∞'].copy()
    
    print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} –∑–∞–ø–∏—Å–µ–π (–≤–∫–ª—é—á–∞—è –≤–∞—Ä–∏–∞–Ω—Ç—ã –Ω–∞–∑–≤–∞–Ω–∏–π)")
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –¥—É–±–ª–∏–∫–∞—Ç–∞–º –∫–æ–¥–æ–≤
    duplicates = df[df.duplicated(subset=['–ù–æ–≤—ã–π –∫–æ–¥'], keep=False)]
    if len(duplicates) > 0:
        unique_codes = duplicates['–ù–æ–≤—ã–π –∫–æ–¥'].nunique()
        print(f"‚ÑπÔ∏è  –ù–∞–π–¥–µ–Ω–æ {unique_codes} –∫–æ–¥–æ–≤ —Å –≤–∞—Ä–∏–∞–Ω—Ç–∞–º–∏ –Ω–∞–∑–≤–∞–Ω–∏–π ({len(duplicates)} –∑–∞–ø–∏—Å–µ–π)")
    
    return df

def drop_old_tables(conn):
    """–£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç–∞—Ä—ã—Ö —Ç–∞–±–ª–∏—Ü"""
    print("\nüóëÔ∏è  –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö —Ç–∞–±–ª–∏—Ü –î–î–°...")
    cursor = conn.cursor()
    
    try:
        cursor.execute("DROP TABLE IF EXISTS master.dds_items CASCADE")
        cursor.execute("DROP TABLE IF EXISTS master.dds_groups CASCADE")
        cursor.execute("DROP TABLE IF EXISTS master.dds_categories CASCADE")
        conn.commit()
        print("‚úÖ –°—Ç–∞—Ä—ã–µ —Ç–∞–±–ª–∏—Ü—ã —É–¥–∞–ª–µ–Ω—ã")
    except Exception as e:
        conn.rollback()
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        raise

def create_schema(conn):
    """–°–æ–∑–¥–∞–Ω–∏–µ —Å—Ö–µ–º—ã"""
    print("\nüìê –°–æ–∑–¥–∞–Ω–∏–µ —Å—Ö–µ–º—ã...")
    cursor = conn.cursor()
    
    schema = """
    -- –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –î–î–°
    CREATE TABLE master.dds_categories (
        id SERIAL PRIMARY KEY,
        code VARCHAR(20) UNIQUE NOT NULL,
        name_ru VARCHAR(200) NOT NULL,
        activity_type VARCHAR(50) NOT NULL,
        direction VARCHAR(20) NOT NULL,
        sort_order INTEGER NOT NULL,
        is_active BOOLEAN DEFAULT TRUE,
        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
    );

    -- –ì—Ä—É–ø–ø—ã –î–î–°
    CREATE TABLE master.dds_groups (
        id SERIAL PRIMARY KEY,
        name_ru VARCHAR(200) NOT NULL,
        category_id INTEGER NOT NULL REFERENCES master.dds_categories(id) ON DELETE RESTRICT,
        sort_order INTEGER,
        is_active BOOLEAN DEFAULT TRUE,
        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
        UNIQUE(name_ru, category_id)
    );

    -- –°—Ç–∞—Ç—å–∏ –î–î–° (–Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ)
    CREATE TABLE master.dds_items (
        id SERIAL PRIMARY KEY,
        code VARCHAR(20) UNIQUE NOT NULL,
        name_ru VARCHAR(500) NOT NULL,
        category_id INTEGER NOT NULL REFERENCES master.dds_categories(id) ON DELETE RESTRICT,
        group_id INTEGER NOT NULL REFERENCES master.dds_groups(id) ON DELETE RESTRICT,
        sort_order INTEGER,
        is_active BOOLEAN DEFAULT TRUE,
        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
    );

    -- –ú–∞–ø–ø–∏–Ω–≥ —Å—Ç–∞—Ä—ã—Ö –Ω–∞–∑–≤–∞–Ω–∏–π –Ω–∞ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ —Å—Ç–∞—Ç—å–∏
    CREATE TABLE master.dds_items_mapping (
        id SERIAL PRIMARY KEY,
        dds_item_id INTEGER NOT NULL REFERENCES master.dds_items(id) ON DELETE CASCADE,
        old_name VARCHAR(500) NOT NULL,
        old_id INTEGER,
        source_system VARCHAR(50) DEFAULT 'legacy',
        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
        UNIQUE(old_name, source_system)
    );

    -- –ò–Ω–¥–µ–∫—Å—ã
    CREATE INDEX idx_dds_items_code ON master.dds_items(code);
    CREATE INDEX idx_dds_items_category ON master.dds_items(category_id);
    CREATE INDEX idx_dds_items_group ON master.dds_items(group_id);
    CREATE INDEX idx_dds_groups_category ON master.dds_groups(category_id);
    CREATE INDEX idx_dds_mapping_item ON master.dds_items_mapping(dds_item_id);
    CREATE INDEX idx_dds_mapping_old_name ON master.dds_items_mapping(old_name);

    -- –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏
    COMMENT ON TABLE master.dds_categories IS '–ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –¥–≤–∏–∂–µ–Ω–∏—è –¥–µ–Ω–µ–∂–Ω—ã—Ö —Å—Ä–µ–¥—Å—Ç–≤ (7)';
    COMMENT ON TABLE master.dds_groups IS '–ì—Ä—É–ø–ø—ã —Å—Ç–∞—Ç–µ–π –î–î–° (~30)';
    COMMENT ON TABLE master.dds_items IS '–ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ —Å—Ç–∞—Ç—å–∏ –î–î–° (—É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∫–æ–¥—ã)';
    COMMENT ON TABLE master.dds_items_mapping IS '–ú–∞–ø–ø–∏–Ω–≥ —Å—Ç–∞—Ä—ã—Ö –Ω–∞–∑–≤–∞–Ω–∏–π —Å—Ç–∞—Ç–µ–π –Ω–∞ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ';
    """
    
    try:
        cursor.execute(schema)
        conn.commit()
        print("‚úÖ –°—Ö–µ–º–∞ —Å–æ–∑–¥–∞–Ω–∞")
    except Exception as e:
        conn.rollback()
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        raise

def insert_categories(conn, df):
    """–í—Å—Ç–∞–≤–∫–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–π"""
    print("\nüì• –ó–∞–≥—Ä—É–∑–∫–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–π...")
    cursor = conn.cursor()
    
    # –ü–æ–ª—É—á–∏—Ç—å —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
    categories = df['–í–∏–¥ –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç–∏'].unique()
    
    category_ids = {}
    for idx, category_name in enumerate(sorted(categories), 1):
        code = CATEGORY_MAPPING.get(category_name)
        if not code:
            print(f"‚ö†Ô∏è  –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è: {category_name}")
            continue
        
        activity_type = ACTIVITY_MAPPING.get(category_name)
        direction = 'inflow' if '–ü–æ—Å—Ç—É–ø–ª–µ–Ω–∏—è' in category_name else ('outflow' if '–ü–ª–∞—Ç–µ–∂–∏' in category_name else 'transfer')
        
        cursor.execute("""
            INSERT INTO master.dds_categories (code, name_ru, activity_type, direction, sort_order)
            VALUES (%s, %s, %s, %s, %s)
            RETURNING id
        """, (code, category_name, activity_type, direction, idx))
        
        category_ids[category_name] = cursor.fetchone()[0]
    
    conn.commit()
    print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–π: {len(category_ids)}")
    return category_ids

def insert_groups(conn, df, category_ids):
    """–í—Å—Ç–∞–≤–∫–∞ –≥—Ä—É–ø–ø"""
    print("\nüì• –ó–∞–≥—Ä—É–∑–∫–∞ –≥—Ä—É–ø–ø...")
    cursor = conn.cursor()
    
    # –ü–æ–ª—É—á–∏—Ç—å —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –ø–∞—Ä—ã (–∫–∞—Ç–µ–≥–æ—Ä–∏—è, –≥—Ä—É–ø–ø–∞)
    groups = df[['–í–∏–¥ –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç–∏', '–ì—Ä—É–ø–ø–∞ —Å—Ç–∞—Ç—å–∏']].drop_duplicates()
    
    group_ids = {}
    for idx, (_, row) in enumerate(groups.iterrows(), 1):
        category_name = row['–í–∏–¥ –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç–∏']
        group_name = row['–ì—Ä—É–ø–ø–∞ —Å—Ç–∞—Ç—å–∏']
        
        if pd.isna(group_name) or group_name == '':
            group_name = '–ë–µ–∑ –≥—Ä—É–ø–ø—ã'
        
        category_id = category_ids.get(category_name)
        if not category_id:
            continue
        
        cursor.execute("""
            INSERT INTO master.dds_groups (name_ru, category_id, sort_order)
            VALUES (%s, %s, %s)
            ON CONFLICT (name_ru, category_id) DO NOTHING
            RETURNING id
        """, (group_name, category_id, idx))
        
        result = cursor.fetchone()
        if result:
            group_ids[(category_name, group_name)] = result[0]
        else:
            # –ï—Å–ª–∏ —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, –ø–æ–ª—É—á–∏—Ç—å id
            cursor.execute("""
                SELECT id FROM master.dds_groups 
                WHERE name_ru = %s AND category_id = %s
            """, (group_name, category_id))
            group_ids[(category_name, group_name)] = cursor.fetchone()[0]
    
    conn.commit()
    print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –≥—Ä—É–ø–ø: {len(group_ids)}")
    return group_ids

def insert_items(conn, df, category_ids, group_ids):
    """–í—Å—Ç–∞–≤–∫–∞ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π –∏ –º–∞–ø–ø–∏–Ω–≥–∞"""
    print("\nüì• –ó–∞–≥—Ä—É–∑–∫–∞ —Å—Ç–∞—Ç–µ–π...")
    cursor = conn.cursor()
    
    # –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ –∫–æ–¥—É (–Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–∞—è —Å—Ç–∞—Ç—å—è)
    unique_items = df.groupby('–ù–æ–≤—ã–π –∫–æ–¥').first().reset_index()
    
    print(f"   –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π: {len(unique_items)}")
    
    # –°–ª–æ–≤–∞—Ä—å –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è id –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π
    item_ids = {}
    
    # –í—Å—Ç–∞–≤–∫–∞ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π
    for idx, row in unique_items.iterrows():
        code = row['–ù–æ–≤—ã–π –∫–æ–¥']
        name = row['–ù–∞–∑–≤–∞–Ω–∏–µ —Å—Ç–∞—Ç—å–∏']
        category_name = row['–í–∏–¥ –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç–∏']
        group_name = row['–ì—Ä—É–ø–ø–∞ —Å—Ç–∞—Ç—å–∏']
        
        if pd.isna(group_name) or group_name == '':
            group_name = '–ë–µ–∑ –≥—Ä—É–ø–ø—ã'
        
        category_id = category_ids.get(category_name)
        group_id = group_ids.get((category_name, group_name))
        
        if not category_id or not group_id:
            print(f"‚ö†Ô∏è  –ü—Ä–æ–ø—É—Å–∫ —Å—Ç–∞—Ç—å–∏ {code}: –Ω–µ—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∏–ª–∏ –≥—Ä—É–ø–ø—ã")
            continue
        
        cursor.execute("""
            INSERT INTO master.dds_items (code, name_ru, category_id, group_id, sort_order)
            VALUES (%s, %s, %s, %s, %s)
            RETURNING id
        """, (code, name, category_id, group_id, idx + 1))
        
        item_ids[code] = cursor.fetchone()[0]
    
    conn.commit()
    print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π: {len(item_ids)}")
    
    # –¢–µ–ø–µ—Ä—å –¥–æ–±–∞–≤–ª—è–µ–º –º–∞–ø–ø–∏–Ω–≥ –¥–ª—è –≤—Å–µ—Ö –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –Ω–∞–∑–≤–∞–Ω–∏–π
    print("\nüì• –°–æ–∑–¥–∞–Ω–∏–µ –º–∞–ø–ø–∏–Ω–≥–∞ –Ω–∞–∑–≤–∞–Ω–∏–π...")
    
    mapping_records = []
    for _, row in df.iterrows():
        code = row['–ù–æ–≤—ã–π –∫–æ–¥']
        name = row['–ù–∞–∑–≤–∞–Ω–∏–µ —Å—Ç–∞—Ç—å–∏']
        old_id = row.get('ID')
        
        item_id = item_ids.get(code)
        if not item_id:
            continue
        
        mapping_records.append((
            item_id,
            name,
            int(old_id) if pd.notna(old_id) else None,
            'legacy'
        ))
    
    # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –ø–æ (dds_item_id, old_name)
    seen = set()
    unique_mappings = []
    for rec in mapping_records:
        key = (rec[0], rec[1])  # (item_id, old_name)
        if key not in seen:
            seen.add(key)
            unique_mappings.append(rec)
    
    execute_batch(cursor, """
        INSERT INTO master.dds_items_mapping (dds_item_id, old_name, old_id, source_system)
        VALUES (%s, %s, %s, %s)
        ON CONFLICT (old_name, source_system) DO NOTHING
    """, unique_mappings, page_size=100)
    
    conn.commit()
    print(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ –º–∞–ø–ø–∏–Ω–≥–æ–≤: {len(unique_mappings)}")
    
    return item_ids

def print_statistics(conn):
    """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞"""
    print("\nüìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê")
    cursor = conn.cursor()
    
    cursor.execute("SELECT COUNT(*) FROM master.dds_categories")
    print(f"–ö–∞—Ç–µ–≥–æ—Ä–∏–π: {cursor.fetchone()[0]}")
    
    cursor.execute("SELECT COUNT(*) FROM master.dds_groups")
    print(f"–ì—Ä—É–ø–ø: {cursor.fetchone()[0]}")
    
    cursor.execute("SELECT COUNT(*) FROM master.dds_items")
    items_count = cursor.fetchone()[0]
    print(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π: {items_count}")
    
    cursor.execute("SELECT COUNT(*) FROM master.dds_items_mapping")
    mapping_count = cursor.fetchone()[0]
    print(f"–í–∞—Ä–∏–∞–Ω—Ç–æ–≤ –Ω–∞–∑–≤–∞–Ω–∏–π: {mapping_count}")
    
    cursor.execute("""
        SELECT c.name_ru, COUNT(DISTINCT i.id)
        FROM master.dds_categories c
        LEFT JOIN master.dds_items i ON c.id = i.category_id
        GROUP BY c.name_ru, c.sort_order
        ORDER BY c.sort_order
    """)
    print("\n–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º:")
    for cat, cnt in cursor.fetchall():
        print(f"  {cat}: {cnt}")
    
    # –ü—Ä–∏–º–µ—Ä—ã —Å—Ç–∞—Ç–µ–π —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ –≤–∞—Ä–∏–∞–Ω—Ç–∞–º–∏
    cursor.execute("""
        SELECT 
            i.code,
            i.name_ru as canonical_name,
            COUNT(m.id) as variants_count,
            STRING_AGG(DISTINCT m.old_name, ' | ') as variants
        FROM master.dds_items i
        JOIN master.dds_items_mapping m ON i.id = m.dds_item_id
        GROUP BY i.code, i.name_ru
        HAVING COUNT(m.id) > 1
        ORDER BY variants_count DESC
        LIMIT 5
    """)
    
    multi_variants = cursor.fetchall()
    if multi_variants:
        print(f"\n–°—Ç–∞—Ç—å–∏ —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ –≤–∞—Ä–∏–∞–Ω—Ç–∞–º–∏ –Ω–∞–∑–≤–∞–Ω–∏–π (—Ç–æ–ø-5):")
        for code, canonical, cnt, variants in multi_variants:
            print(f"  {code} ({cnt} –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤):")
            print(f"    –û—Å–Ω–æ–≤–Ω–æ–µ: {canonical}")
            print(f"    –í–∞—Ä–∏–∞–Ω—Ç—ã: {variants[:100]}...")


def main():
    print("=" * 70)
    print("üîÑ –ó–ê–ì–†–£–ó–ö–ê –°–ü–†–ê–í–û–ß–ù–ò–ö–ê –î–î–°")
    print("=" * 70)
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ Excel
    df = load_excel()
    
    # –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ
    print("\nüîå –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ PostgreSQL...")
    try:
        conn = psycopg2.connect(**DB_CONFIG)
        print("‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–æ")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        sys.exit(1)
    
    try:
        # 1. –£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç–∞—Ä—ã—Ö —Ç–∞–±–ª–∏—Ü
        drop_old_tables(conn)
        
        # 2. –°–æ–∑–¥–∞–Ω–∏–µ —Å—Ö–µ–º—ã
        create_schema(conn)
        
        # 3. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        category_ids = insert_categories(conn, df)
        group_ids = insert_groups(conn, df, category_ids)
        insert_items(conn, df, category_ids, group_ids)
        
        # 4. –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        print_statistics(conn)
        
        print("\n" + "=" * 70)
        print("‚úÖ –ó–ê–ì–†–£–ó–ö–ê –ó–ê–í–ï–†–®–ï–ù–ê –£–°–ü–ï–®–ù–û")
        print("=" * 70)
        
    except Exception as e:
        print(f"\n‚ùå –û–®–ò–ë–ö–ê: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
    finally:
        conn.close()

if __name__ == '__main__':
    main()
