#!/usr/bin/env python3
"""
–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∏ –æ–±–æ–≥–∞—â–µ–Ω–∏–µ –∫–æ–º–ø–∞–Ω–∏–π:
1. –ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏—è: "–ù–ê–ó–í–ê–ù–ò–ï –û–ü–§" (–ü–ê–†–¢–ù–ï–† –û–û–û, –ê–õ–¨–Ø–ù–° –û–û–û)
2. –û–±–æ–≥–∞—â–∞–µ—Ç —á–µ—Ä–µ–∑ DaData API
3. –ù–∞—Ö–æ–¥–∏—Ç –∏ –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç –¥—É–±–ª–∏–∫–∞—Ç—ã –ø–æ –ò–ù–ù
"""

import sys
from pathlib import Path
import time
import re
from datetime import datetime
import requests
import psycopg2
from psycopg2.extras import RealDictCursor

sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from finance_core.config import (
    POSTGRES_HOST, POSTGRES_PORT, POSTGRES_USER, POSTGRES_PASSWORD, POSTGRES_DB
)

# DaData API
DADATA_API_KEY = "bd5917c0a335f0af9cceee3f0248b749898d3116"
DADATA_SUGGEST_URL = "https://suggestions.dadata.ru/suggestions/api/4_1/rs/suggest/party"

HEADERS = {
    "Authorization": f"Token {DADATA_API_KEY}",
    "Content-Type": "application/json",
    "Accept": "application/json"
}

POSTGRES_CONFIG = {
    'host': POSTGRES_HOST,
    'port': POSTGRES_PORT,
    'user': POSTGRES_USER,
    'password': POSTGRES_PASSWORD,
    'dbname': POSTGRES_DB
}


def normalize_company_name(name: str) -> str:
    """
    –ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–æ–º–ø–∞–Ω–∏–∏ –ø–æ –ø—Ä–∞–≤–∏–ª–∞–º:
    - –£–±–∏—Ä–∞–µ–º –∫–∞–≤—ã—á–∫–∏
    - –ü–µ—Ä–µ—Å—Ç–∞–≤–ª—è–µ–º –û–ü–§ –≤ –∫–æ–Ω–µ—Ü: –û–û–û "–ü–ê–†–¢–ù–ï–†" -> –ü–ê–†–¢–ù–ï–† –û–û–û
    - –î–ª—è –ò–ü: –ò–ü –ò–≤–∞–Ω–æ–≤ -> –ò–≤–∞–Ω–æ–≤ –ò–≤–∞–Ω –ò–≤–∞–Ω–æ–≤–∏—á –ò–ü
    - –§–∏–∑–ª–∏—Ü–∞ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π
    """
    if not name:
        return name
    
    # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ –∫–∞–≤—ã—á–∫–∏
    name = name.strip()
    name = name.replace('"', '').replace('"', '').replace('"', '')
    name = ' '.join(name.split())  # –ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã –≤ –æ–¥–∏–Ω
    
    # –°–ø–∏—Å–æ–∫ –û–ü–§
    opf_list = [
        '–û–û–û', '–û–ê–û', '–ó–ê–û', '–ê–û', '–ò–ü', 
        '–ü–ê–û', '–ù–ê–û', '–ì–£–ü', '–ú–£–ü',
        '–¢–û–û', '–¢–î–û', '–û–î–û'
    ]
    
    # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ –û–ü–§ –≤ –Ω–∞—á–∞–ª–µ/–∫–æ–Ω—Ü–µ
    opf_start_pattern = r'^(' + '|'.join(opf_list) + r')\s+[""¬´]?(.+?)[""¬ª]?$'
    opf_end_pattern = r'^[""¬´]?(.+?)[""¬ª]?\s+(' + '|'.join(opf_list) + r')$'
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –û–ü–§ –≤ –Ω–∞—á–∞–ª–µ: –û–û–û "–ü–ê–†–¢–ù–ï–†" -> –ü–ê–†–¢–ù–ï–† –û–û–û
    match = re.match(opf_start_pattern, name, re.IGNORECASE)
    if match:
        opf = match.group(1).upper()
        company_name = match.group(2).strip()
        return f"{company_name} {opf}"
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –û–ü–§ –≤ –∫–æ–Ω—Ü–µ: "–ü–ê–†–¢–ù–ï–†" –û–û–û -> –ü–ê–†–¢–ù–ï–† –û–û–û
    match = re.match(opf_end_pattern, name, re.IGNORECASE)
    if match:
        company_name = match.group(1).strip()
        opf = match.group(2).upper()
        return f"{company_name} {opf}"
    
    # –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è –ò–ü —Å –§–ò–û
    if name.upper().startswith('–ò–ü '):
        # –ò–ü –ò–≤–∞–Ω–æ–≤ –ò–≤–∞–Ω –ò–≤–∞–Ω–æ–≤–∏—á -> –ò–≤–∞–Ω–æ–≤ –ò–≤–∞–Ω –ò–≤–∞–Ω–æ–≤–∏—á –ò–ü
        fio = name[3:].strip()
        return f"{fio} –ò–ü"
    
    # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –û–ü–§ - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å (–≤–æ–∑–º–æ–∂–Ω–æ —Ñ–∏–∑–ª–∏—Ü–æ)
    return name


class CompanyNormalizer:
    def __init__(self):
        self.pg_conn = psycopg2.connect(**POSTGRES_CONFIG)
        self.stats = {
            'total': 0,
            'normalized': 0,
            'enriched': 0,
            'not_found': 0,
            'errors': 0,
            'duplicates_merged': 0
        }
    
    def __del__(self):
        if hasattr(self, 'pg_conn'):
            self.pg_conn.close()
    
    def normalize_all_names(self):
        """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –≤—Å–µ –Ω–∞–∑–≤–∞–Ω–∏—è –∫–æ–º–ø–∞–Ω–∏–π"""
        print("\n" + "="*80)
        print("–≠–¢–ê–ü 1: –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –Ω–∞–∑–≤–∞–Ω–∏–π –∫–æ–º–ø–∞–Ω–∏–π")
        print("="*80)
        
        cursor = self.pg_conn.cursor(cursor_factory=RealDictCursor)
        cursor.execute("SELECT id, company_name FROM master.companies ORDER BY id")
        companies = cursor.fetchall()
        
        for company in companies:
            old_name = company['company_name']
            new_name = normalize_company_name(old_name)
            
            if old_name != new_name:
                print(f"[{company['id']}] {old_name}")
                print(f"      ‚Üí {new_name}")
                
                cursor.execute("""
                    UPDATE master.companies 
                    SET company_name = %s 
                    WHERE id = %s
                """, (new_name, company['id']))
                
                self.stats['normalized'] += 1
        
        self.pg_conn.commit()
        print(f"\n‚úÖ –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–æ: {self.stats['normalized']} –∫–æ–º–ø–∞–Ω–∏–π")
    
    def dadata_suggest(self, name: str):
        """–ü–æ–∏—Å–∫ –∫–æ–º–ø–∞–Ω–∏–∏ –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é"""
        try:
            response = requests.post(
                DADATA_SUGGEST_URL,
                json={"query": name, "count": 1},
                headers=HEADERS,
                timeout=10
            )
            
            if response.status_code != 200:
                return None
            
            suggestions = response.json().get("suggestions", [])
            return suggestions[0] if suggestions else None
            
        except Exception as e:
            print(f"‚ö† –û—à–∏–±–∫–∞ API: {e}")
            return None
    
    def extract_data(self, suggestion):
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ –æ—Ç–≤–µ—Ç–∞ DaData"""
        if not suggestion:
            return None
        
        data = suggestion.get("data", {})
        
        return {
            "inn": data.get("inn"),
            "ogrn": data.get("ogrn"),
            "full_name": data.get("name", {}).get("full_with_opf"),
            "short_name": data.get("name", {}).get("short_with_opf"),
            "address": data.get("address", {}).get("value"),
            "director_name": (data.get("management") or {}).get("name"),
            "phone": (data.get("phones", [None])[0] if data.get("phones") else None),
            "status": (data.get("state") or {}).get("status"),
            "registration_date": (data.get("state") or {}).get("registration_date"),
            "okved": data.get("okved")
        }
    
    def enrich_companies(self, limit=None):
        """–û–±–æ–≥–∞—â–∞–µ—Ç –∫–æ–º–ø–∞–Ω–∏–∏ —á–µ—Ä–µ–∑ DaData"""
        print("\n" + "="*80)
        print("–≠–¢–ê–ü 2: –û–±–æ–≥–∞—â–µ–Ω–∏–µ —á–µ—Ä–µ–∑ DaData API")
        print("="*80)
        
        cursor = self.pg_conn.cursor(cursor_factory=RealDictCursor)
        
        query = """
            SELECT id, company_name, inn 
            FROM master.companies 
            WHERE enrichment_status = 'pending' OR inn IS NULL
            ORDER BY id
        """
        if limit:
            query += f" LIMIT {limit}"
        
        cursor.execute(query)
        companies = cursor.fetchall()
        
        print(f"–ö –æ–±—Ä–∞–±–æ—Ç–∫–µ: {len(companies)} –∫–æ–º–ø–∞–Ω–∏–π\n")
        
        for idx, company in enumerate(companies, 1):
            print(f"[{idx}/{len(companies)}] {company['company_name']}")
            
            suggestion = self.dadata_suggest(company['company_name'])
            
            if suggestion:
                data = self.extract_data(suggestion)
                
                if data and data.get('inn'):
                    cursor.execute("""
                        UPDATE master.companies
                        SET 
                            inn = %s,
                            ogrn = %s,
                            full_name = %s,
                            address = %s,
                            director_name = %s,
                            phone = %s,
                            status = %s,
                            okved = %s,
                            enriched_at = NOW(),
                            enrichment_status = 'enriched'
                        WHERE id = %s
                    """, (
                        data['inn'], data['ogrn'], data['full_name'],
                        data['address'], data['director_name'], data['phone'],
                        data['status'], data['okved'], company['id']
                    ))
                    
                    print(f"  ‚úÖ –ò–ù–ù: {data['inn']}, {data['full_name']}")
                    self.stats['enriched'] += 1
                else:
                    cursor.execute("""
                        UPDATE master.companies 
                        SET enrichment_status = 'not_found', enriched_at = NOW()
                        WHERE id = %s
                    """, (company['id'],))
                    print(f"  ‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ")
                    self.stats['not_found'] += 1
            else:
                cursor.execute("""
                    UPDATE master.companies 
                    SET enrichment_status = 'not_found', enriched_at = NOW()
                    WHERE id = %s
                """, (company['id'],))
                print(f"  ‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ")
                self.stats['not_found'] += 1
            
            self.pg_conn.commit()
            time.sleep(0.3)  # Rate limit
        
        print(f"\n‚úÖ –û–±–æ–≥–∞—â–µ–Ω–æ: {self.stats['enriched']}")
        print(f"‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ: {self.stats['not_found']}")
    
    def find_and_merge_duplicates(self):
        """–ù–∞—Ö–æ–¥–∏—Ç –¥—É–±–ª–∏–∫–∞—Ç—ã –ø–æ –ò–ù–ù –∏ –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç –∏—Ö"""
        print("\n" + "="*80)
        print("–≠–¢–ê–ü 3: –ü–æ–∏—Å–∫ –∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤")
        print("="*80)
        
        cursor = self.pg_conn.cursor(cursor_factory=RealDictCursor)
        
        # –ù–∞—Ö–æ–¥–∏–º –¥—É–±–ª–∏–∫–∞—Ç—ã –ø–æ –ò–ù–ù
        cursor.execute("""
            SELECT 
                inn,
                COUNT(*) as count,
                ARRAY_AGG(id ORDER BY id) as company_ids,
                ARRAY_AGG(company_name ORDER BY id) as names
            FROM master.companies
            WHERE inn IS NOT NULL AND inn != ''
            GROUP BY inn
            HAVING COUNT(*) > 1
            ORDER BY count DESC
        """)
        
        duplicates = cursor.fetchall()
        
        if not duplicates:
            print("‚úÖ –î—É–±–ª–∏–∫–∞—Ç–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
            return
        
        print(f"–ù–∞–π–¥–µ–Ω–æ {len(duplicates)} –≥—Ä—É–ø–ø –¥—É–±–ª–∏–∫–∞—Ç–æ–≤:\n")
        
        for dup in duplicates:
            print(f"–ò–ù–ù: {dup['inn']}")
            print(f"  –ö–æ–º–ø–∞–Ω–∏–π: {dup['count']}")
            for i, (cid, name) in enumerate(zip(dup['company_ids'], dup['names']), 1):
                print(f"  {i}. [{cid}] {name}")
            
            # –û—Å—Ç–∞–≤–ª—è–µ–º –ø–µ—Ä–≤—É—é (—Å –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–º ID), –æ—Å—Ç–∞–ª—å–Ω—ã–µ –ø–æ–º–µ—á–∞–µ–º
            master_id = dup['company_ids'][0]
            duplicate_ids = dup['company_ids'][1:]
            
            print(f"  ‚Üí –û—Å—Ç–∞–≤–ª—è–µ–º [{master_id}], –ø–æ–º–µ—á–∞–µ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ –∫–∞–∫ –¥—É–±–ª–∏–∫–∞—Ç—ã")
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Å—ã–ª–∫–∏ –≤ history.osv_detail
            for dup_id in duplicate_ids:
                cursor.execute("""
                    UPDATE history.osv_9m_summary 
                    SET company_id = %s 
                    WHERE company_id = %s
                """, (master_id, dup_id))
                
                cursor.execute("""
                    UPDATE history.cashflow_movements 
                    SET company_id = %s 
                    WHERE company_id = %s
                """, (master_id, dup_id))
                
                # –ü–æ–º–µ—á–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç –∫–∞–∫ –Ω–µ–∞–∫—Ç–∏–≤–Ω—ã–π
                cursor.execute("""
                    UPDATE master.companies 
                    SET 
                        is_active = FALSE,
                        enrichment_status = 'duplicate'
                    WHERE id = %s
                """, (dup_id,))
            
            self.stats['duplicates_merged'] += len(duplicate_ids)
            self.pg_conn.commit()
            print()
        
        print(f"‚úÖ –û–±—ä–µ–¥–∏–Ω–µ–Ω–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {self.stats['duplicates_merged']}")
    
    def run(self, enrich_limit=None):
        """–ü–æ–ª–Ω—ã–π —Ü–∏–∫–ª –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
        print("\n" + "="*80)
        print("üöÄ –ù–û–†–ú–ê–õ–ò–ó–ê–¶–ò–Ø –ò –û–ë–û–ì–ê–©–ï–ù–ò–ï –ö–û–ú–ü–ê–ù–ò–ô")
        print("="*80)
        
        cursor = self.pg_conn.cursor()
        cursor.execute("SELECT COUNT(*) FROM master.companies")
        self.stats['total'] = cursor.fetchone()[0]
        print(f"–í—Å–µ–≥–æ –∫–æ–º–ø–∞–Ω–∏–π: {self.stats['total']}")
        
        # –≠—Ç–∞–ø 1: –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –Ω–∞–∑–≤–∞–Ω–∏–π
        self.normalize_all_names()
        
        # –≠—Ç–∞–ø 2: –û–±–æ–≥–∞—â–µ–Ω–∏–µ —á–µ—Ä–µ–∑ DaData
        self.enrich_companies(limit=enrich_limit)
        
        # –≠—Ç–∞–ø 3: –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
        self.find_and_merge_duplicates()
        
        # –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        print("\n" + "="*80)
        print("‚úÖ –û–ë–†–ê–ë–û–¢–ö–ê –ó–ê–í–ï–†–®–ï–ù–ê")
        print("="*80)
        print(f"–í—Å–µ–≥–æ –∫–æ–º–ø–∞–Ω–∏–π:        {self.stats['total']}")
        print(f"–ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–æ:         {self.stats['normalized']}")
        print(f"–û–±–æ–≥–∞—â–µ–Ω–æ:             {self.stats['enriched']}")
        print(f"–ù–µ –Ω–∞–π–¥–µ–Ω–æ:            {self.stats['not_found']}")
        print(f"–û–±—ä–µ–¥–∏–Ω–µ–Ω–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {self.stats['duplicates_merged']}")
        print("="*80)


def main():
    import argparse
    parser = argparse.ArgumentParser(description='–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∏ –æ–±–æ–≥–∞—â–µ–Ω–∏–µ –∫–æ–º–ø–∞–Ω–∏–π')
    parser.add_argument('--limit', type=int, help='–û–≥—Ä–∞–Ω–∏—á–∏—Ç—å –æ–±–æ–≥–∞—â–µ–Ω–∏–µ N –∫–æ–º–ø–∞–Ω–∏–π')
    parser.add_argument('--normalize-only', action='store_true', help='–¢–æ–ª—å–∫–æ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –±–µ–∑ API')
    
    args = parser.parse_args()
    
    normalizer = CompanyNormalizer()
    
    if args.normalize_only:
        normalizer.normalize_all_names()
    else:
        normalizer.run(enrich_limit=args.limit)


if __name__ == "__main__":
    main()
