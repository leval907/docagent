# üöÄ DocAgent - Complete Production Pipeline

**Full-stack documentation processing pipeline** —Å PostgreSQL 18, ChromaDB, Prefect, FastAPI –∏ DuckDB.

## üì¶ –¢–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π —Å—Ç–µ–∫

- **üï∑Ô∏è Crawler**: Crawl4AI + Playwright (JavaScript support)
- **üóÑÔ∏è Metadata DB**: PostgreSQL 18 + pgvector
- **üß† Vector DB**: ChromaDB –¥–ª—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞
- **‚ö° Orchestration**: Prefect 2.0 –¥–ª—è workflow management
- **üåê API**: FastAPI –¥–ª—è REST endpoints
- **üìä Analytics**: DuckDB –¥–ª—è –±—ã—Å—Ç—Ä–æ–π –∞–Ω–∞–ª–∏—Ç–∏–∫–∏
- **‚òÅÔ∏è Storage**: S3-compatible (Beget, AWS, MinIO)

## üèóÔ∏è –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Crawl4AI   ‚îÇ -> ‚îÇ  PostgreSQL  ‚îÇ -> ‚îÇ ChromaDB‚îÇ -> ‚îÇ  FastAPI   ‚îÇ
‚îÇ  (Scraper)  ‚îÇ    ‚îÇ  (Metadata)  ‚îÇ    ‚îÇ (Vector)‚îÇ    ‚îÇ    (API)   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ                   ‚îÇ                  ‚îÇ              ‚îÇ
       v                   v                  v              v
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ     S3      ‚îÇ    ‚îÇ   Prefect    ‚îÇ    ‚îÇ DuckDB  ‚îÇ    ‚îÇ   Client   ‚îÇ
‚îÇ  (Storage)  ‚îÇ    ‚îÇ(Orchestrator)‚îÇ    ‚îÇ(Analytics)‚îÇ   ‚îÇ   Apps     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üéØ –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏

‚úÖ **Intelligent Crawling** - Async –∫—Ä–∞—É–ª–∏–Ω–≥ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π JavaScript  
‚úÖ **Vector Search** - –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ —á–µ—Ä–µ–∑ ChromaDB  
‚úÖ **Workflow Automation** - Prefect flows –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏  
‚úÖ **REST API** - FastAPI endpoints –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏  
‚úÖ **Analytics** - DuckDB –¥–ª—è –±—ã—Å—Ç—Ä—ã—Ö SQL-–∑–∞–ø—Ä–æ—Å–æ–≤  
‚úÖ **S3 Storage** - –°–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å Beget, AWS, MinIO  
‚úÖ **PostgreSQL 18** - –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Å pgvector –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π  

## üöÄ –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç

### 1. –ö–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞

```bash
git clone https://github.com/leval907/docagent.git
cd docagent

cp .env.example .env
nano .env  # –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å credentials
```

### 2. –ó–∞–ø—É—Å–∫ –≤—Å–µ–≥–æ —Å—Ç–µ–∫–∞

```bash
# –°–æ–∑–¥–∞—Ç—å —Å–µ—Ç—å (–µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç)
docker network create ducem-net

# –ó–∞–ø—É—Å—Ç–∏—Ç—å –≤—Å–µ —Å–µ—Ä–≤–∏—Å—ã
docker compose up -d

# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å—Ç–∞—Ç—É—Å
docker compose ps
```

### 3. –î–æ—Å—Ç—É–ø –∫ —Å–µ—Ä–≤–∏—Å–∞–º

- **FastAPI Docs**: http://localhost:8080/docs
- **Prefect UI**: http://localhost:4200
- **ChromaDB**: http://localhost:8000
- **PostgreSQL**: localhost:5436

### 4. –ó–∞–ø—É—Å–∫ –∫—Ä–∞—É–ª–µ—Ä–∞

```bash
# –ß–µ—Ä–µ–∑ Docker Compose
docker compose --profile crawler run --rm -e APP=openspg crawler

# –ò–ª–∏ –Ω–∞–ø—Ä—è–º—É—é
python scripts/crawl_and_clean.py --app openspg \
  --s3-bucket your-bucket \
  --s3-endpoint https://s3.ru1.storage.beget.cloud
```

### 5. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ API

```bash
# –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è
curl http://localhost:8080/health

# –°–ø–∏—Å–æ–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
curl http://localhost:8080/documents?app_id=openspg

# –í–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫
curl -X POST http://localhost:8080/search \
  -H "Content-Type: application/json" \
  -d '{"query": "knowledge graph", "limit": 5}'

# –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
curl http://localhost:8080/stats/analytics
```

## üìä –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Å–µ—Ä–≤–∏—Å–æ–≤

### PostgreSQL 18 + pgvector
- **–ü–æ—Ä—Ç**: 5436
- **–ë–∞–∑–∞**: `docagent`
- **–¢–∞–±–ª–∏—Ü—ã**: `documents`, `crawl_stats`, `document_embeddings`
- **–†–∞—Å—à–∏—Ä–µ–Ω–∏—è**: `vector` –¥–ª—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞

### ChromaDB
- **–ü–æ—Ä—Ç**: 8000
- **Collection**: `documents`
- **Embeddings**: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è
- **Persistence**: `/opt/docagent/chromadata`

### Prefect
- **–ü–æ—Ä—Ç**: 4200
- **Flows**: `process-documentation`, `scheduled-crawl`
- **Backend**: PostgreSQL –¥–ª—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö

### FastAPI
- **–ü–æ—Ä—Ç**: 8080
- **Endpoints**: `/documents`, `/search`, `/stats`, `/apps`
- **Docs**: Swagger UI –Ω–∞ `/docs`

### DuckDB
- **Path**: `/opt/docagent/data/analytics.duckdb`
- **Usage**: –ë—ã—Å—Ç—Ä–∞—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∞ –ø–æ–≤–µ—Ä—Ö PostgreSQL
- **Attach**: –ü—Ä—è–º–æ–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Postgres

## üîß –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

### .env —Ñ–∞–π–ª

```bash
# S3 (Beget)
AWS_ACCESS_KEY_ID=JQDHVXZY7XFWUHF8LV0S
AWS_SECRET_ACCESS_KEY=pjVG1Zt5G6y8N8eYAmPnKcnnPpfxB3KVCcFrEyfk
S3_ENDPOINT=https://s3.ru1.storage.beget.cloud
S3_BUCKET=db6a1f644d97-la-ducem1

# PostgreSQL
POSTGRES_USER=docagent
POSTGRES_PASSWORD=secure_pass_2025
POSTGRES_DB=docagent
POSTGRES_PORT=5436

# ChromaDB
CHROMA_PORT=8000
CHROMA_URL=http://chromadb:8000

# Prefect
PREFECT_PORT=4200
PREFECT_API_URL=http://prefect-server:4200/api

# FastAPI
API_PORT=8080
CORS_ORIGINS=*

# Network
NETWORK_NAME=ducem-net
NETWORK_EXTERNAL=true
```

## üîÑ Prefect Workflows

### –ó–∞–ø—É—Å–∫ flow –≤—Ä—É—á–Ω—É—é

```bash
# –ó–∞–π—Ç–∏ –≤ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä
docker compose run --rm crawler bash

# –ó–∞–ø—É—Å—Ç–∏—Ç—å flow
python workflows/prefect_flows.py
```

### –î–µ–ø–ª–æ–π flow –≤ Prefect

```python
from workflows.prefect_flows import process_documentation_flow

# –°–æ–∑–¥–∞–Ω–∏–µ deployment
process_documentation_flow.deploy(
    name="openspg-daily",
    work_pool_name="default-agent-pool",
    cron="0 2 * * *",  # –ö–∞–∂–¥—ã–π –¥–µ–Ω—å –≤ 2:00
    parameters={"app_id": "openspg"}
)
```

## üì° API Endpoints

### Documents

```bash
GET  /documents              # –°–ø–∏—Å–æ–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
GET  /documents/{id}         # –î–æ–∫—É–º–µ–Ω—Ç –ø–æ ID
GET  /apps                   # –°–ø–∏—Å–æ–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π
```

### Search

```bash
POST /search                 # –í–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫
{
  "query": "search text",
  "app_id": "openspg",      # –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ
  "limit": 10
}
```

### Statistics

```bash
GET  /stats/crawls           # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫—Ä–∞—É–ª–∏–Ω–≥–∞
GET  /stats/analytics        # DuckDB –∞–Ω–∞–ª–∏—Ç–∏–∫–∞
```

### Health

```bash
GET  /health                 # –°—Ç–∞—Ç—É—Å —Å–µ—Ä–≤–∏—Å–æ–≤
GET  /                       # API info
```

## üîç –í–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫

### –ß–µ—Ä–µ–∑ API

```python
import requests

response = requests.post(
    "http://localhost:8080/search",
    json={
        "query": "How to build knowledge graph?",
        "app_id": "openspg",
        "limit": 5
    }
)

results = response.json()
for result in results:
    print(f"{result['title']}: {result['similarity']:.3f}")
    print(f"  {result['chunk_text'][:200]}...")
```

### –ù–∞–ø—Ä—è–º—É—é —á–µ—Ä–µ–∑ ChromaDB

```python
import chromadb

client = chromadb.HttpClient(host="localhost", port=8000)
collection = client.get_collection("documents")

results = collection.query(
    query_texts=["knowledge graph"],
    n_results=5
)
```

## üìä –ê–Ω–∞–ª–∏—Ç–∏–∫–∞ —Å DuckDB

```sql
-- –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ PostgreSQL
ATTACH 'postgresql://docagent:secure_pass_2025@localhost:5436/docagent' 
AS pg (TYPE postgres);

-- –¢–æ–ø –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
SELECT 
    app_id,
    COUNT(*) as docs,
    SUM(word_count) as total_words
FROM pg.documents
GROUP BY app_id
ORDER BY docs DESC;

-- –î–∏–Ω–∞–º–∏–∫–∞ –∫—Ä–∞—É–ª–∏–Ω–≥–∞
SELECT 
    DATE(completed_at) as date,
    SUM(pages_crawled) as total_pages,
    AVG(duration_seconds) as avg_duration
FROM pg.crawl_stats
GROUP BY date
ORDER BY date DESC;
```

## üîå –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è

### –° Flowise

```yaml
Vector Store: ChromaDB
Host: chromadb:8000  # –µ—Å–ª–∏ –≤ ducem-net
Collection: documents
```

### –° n8n

```json
{
  "url": "http://docagent-api:8080",
  "endpoints": {
    "search": "/search",
    "documents": "/documents"
  }
}
```

### –° OpenSPG

```bash
POSTGRES_URL=postgresql://docagent:secure_pass_2025@postgres18:5432/docagent
VECTOR_DB_URL=http://chromadb:8000
```

## üõ†Ô∏è –†–∞–∑—Ä–∞–±–æ—Ç–∫–∞

### –õ–æ–∫–∞–ª—å–Ω—ã–π –∑–∞–ø—É—Å–∫ (–±–µ–∑ Docker)

```bash
# –í–∏—Ä—Ç—É–∞–ª—å–Ω–æ–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ
python3 -m venv venv
source venv/bin/activate

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
pip install -r requirements.txt
pip install -r requirements.api.txt

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ Playwright
playwright install chromium

# –ó–∞–ø—É—Å–∫ API
uvicorn api.main:app --reload --port 8080

# –ó–∞–ø—É—Å–∫ –∫—Ä–∞—É–ª–µ—Ä–∞
python scripts/crawl_and_clean.py --app openspg
```

### –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ

```bash
# API —Ç–µ—Å—Ç—ã
pytest tests/test_api.py

# Workflow —Ç–µ—Å—Ç—ã
pytest tests/test_workflows.py

# –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã
pytest tests/integration/
```

## üì¶ –î–µ–ø–ª–æ–π –Ω–∞ —Å–µ—Ä–≤–µ—Ä

```bash
# –ù–∞ —Å–µ—Ä–≤–µ—Ä–µ
cd /opt/docagent
git pull origin main

# –ü–µ—Ä–µ—Å–±–æ—Ä–∫–∞ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤
docker compose build --no-cache

# –†–µ—Å—Ç–∞—Ä—Ç —Å–µ—Ä–≤–∏—Å–æ–≤
docker compose down
docker compose up -d

# –ü—Ä–æ–≤–µ—Ä–∫–∞
docker compose ps
docker compose logs -f
```

## üîí –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å

### Firewall

```bash
sudo ufw allow 22/tcp   # SSH
sudo ufw allow 8080/tcp # API (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
sudo ufw deny 5436      # PostgreSQL (–≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π)
sudo ufw deny 8000      # ChromaDB (–≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π)
sudo ufw deny 4200      # Prefect (–≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π)
```

### SSL/TLS –¥–ª—è API

–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ Nginx –∫–∞–∫ reverse proxy:

```nginx
server {
    listen 443 ssl;
    server_name api.yourdomain.com;
    
    ssl_certificate /etc/letsencrypt/live/yourdomain.com/fullchain.pem;
    ssl_certificate_key /etc/letsencrypt/live/yourdomain.com/privkey.pem;
    
    location / {
        proxy_pass http://localhost:8080;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
    }
}
```

## üìà –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥

### Prometheus metrics

FastAPI –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –Ω–∞ `/metrics`

### Grafana dashboard

–ò–º–ø–æ—Ä—Ç–∏—Ä—É–π—Ç–µ `monitoring/grafana-dashboard.json`

### –õ–æ–≥–∏

```bash
# –í—Å–µ —Å–µ—Ä–≤–∏—Å—ã
docker compose logs -f

# –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Å–µ—Ä–≤–∏—Å
docker compose logs -f fastapi
docker compose logs -f crawler
docker compose logs -f prefect-server
```

## üéì –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è

- **[PIPELINE_GUIDE.md](./PIPELINE_GUIDE.md)** - –î–µ—Ç–∞–ª—å–Ω–æ–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ
- **[DOCKER_SETUP.md](./DOCKER_SETUP.md)** - Docker –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
- **[SERVER_DEPLOYMENT.md](./SERVER_DEPLOYMENT.md)** - –î–µ–ø–ª–æ–π –Ω–∞ —Å–µ—Ä–≤–µ—Ä
- **[API Documentation](http://localhost:8080/docs)** - Swagger UI

## ü§ù Contributing

Pull requests –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤—É—é—Ç—Å—è! –°–º. [CONTRIBUTING.md](./CONTRIBUTING.md)

## üìù License

MIT License - —Å–º. [LICENSE](./LICENSE)

## üôè Acknowledgments

- [Crawl4AI](https://github.com/unclecode/crawl4ai) - Intelligent crawling
- [ChromaDB](https://www.trychroma.com/) - Vector database
- [Prefect](https://www.prefect.io/) - Workflow orchestration
- [FastAPI](https://fastapi.tiangolo.com/) - Modern API framework
- [DuckDB](https://duckdb.org/) - Analytical database

---

**‚≠ê Star this repo if you find it useful!**

**üöÄ Ready for production with full observability and scalability!**
